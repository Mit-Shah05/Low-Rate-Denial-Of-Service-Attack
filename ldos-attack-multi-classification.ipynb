{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7816715,"sourceType":"datasetVersion","datasetId":4579389}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import math\nimport numpy as np\nimport pandas as pd\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder \nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import RFE\nimport itertools\nfrom sklearn.utils import resample\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import BernoulliNB \nfrom sklearn import tree\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.calibration import CalibratedClassifierCV\n\nLGR_Classifier = OneVsRestClassifier(\n    LogisticRegression(\n        solver='lbfgs',\n        max_iter=2000,\n        class_weight='balanced',\n        random_state=42\n    )\n)\n\nRF_Classifier = RandomForestClassifier(\n    n_estimators=100,\n    max_depth=15,\n    random_state=42,\n    n_jobs=-1\n)\n\nSVM_Classifier = LinearSVC(\n    C=1.5,\n    class_weight='balanced',\n    max_iter=20000,\n    tol=1e-3,\n    random_state=42\n)\n\nKNN_Classifier = KNeighborsClassifier(\n    n_neighbors=5,\n    n_jobs=-1\n)\n\nBNB_Classifier = BernoulliNB()\n\nDTC_Classifier = tree.DecisionTreeClassifier(\n    criterion='entropy',\n    random_state=42\n)\n","metadata":{"execution":{"iopub.status.busy":"2025-12-26T18:02:50.353578Z","iopub.execute_input":"2025-12-26T18:02:50.353903Z","iopub.status.idle":"2025-12-26T18:02:53.087945Z","shell.execute_reply.started":"2025-12-26T18:02:50.353877Z","shell.execute_reply":"2025-12-26T18:02:53.086609Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Read the dataset\ndata = pd.read_csv('/kaggle/input/cicddos-dataset/cicddos2019_dataset.csv')\n\n# ===============================\n# Increased dataset usage (reduces overfitting)\n# ===============================\nSAMPLE_RATIO = 0.25\n\nsample_size = int(SAMPLE_RATIO * len(data))\nrows = data.sample(n=sample_size, random_state=42)\n\nprint(f\"Using {SAMPLE_RATIO*100}% of dataset: {len(rows)} samples\")\n\nprint(\"Original dataset size:\", len(rows))\n\n# Split the dataset into training and testing sets\nX = rows.drop(columns=['Label'])\ny = rows['Label']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n\nprint(\"Training set size:\", len(X_train), len(y_train))\nprint(\"Testing set size:\", len(X_test), len(y_test))","metadata":{"execution":{"iopub.status.busy":"2025-12-26T18:02:53.089318Z","iopub.execute_input":"2025-12-26T18:02:53.089720Z","iopub.status.idle":"2025-12-26T18:02:55.941486Z","shell.execute_reply.started":"2025-12-26T18:02:53.089698Z","shell.execute_reply":"2025-12-26T18:02:55.940535Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Using 25.0% of dataset: 107842 samples\nOriginal dataset size: 107842\nTraining set size: 75489 75489\nTesting set size: 32353 32353\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ===============================\n# Scale numerical features (explicit dtype casting)\n# ===============================\nscaler = StandardScaler()\nnumerical_cols = X_train.select_dtypes(include=['float64', 'int64']).columns\n\n# Explicitly convert to float to avoid dtype warnings\nX_train[numerical_cols] = X_train[numerical_cols].astype(float)\nX_test[numerical_cols]  = X_test[numerical_cols].astype(float)\n\nX_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\nX_test[numerical_cols]  = scaler.transform(X_test[numerical_cols])","metadata":{"execution":{"iopub.status.busy":"2025-12-26T18:02:55.942423Z","iopub.execute_input":"2025-12-26T18:02:55.942629Z","iopub.status.idle":"2025-12-26T18:02:56.110604Z","shell.execute_reply.started":"2025-12-26T18:02:55.942613Z","shell.execute_reply":"2025-12-26T18:02:56.109638Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# # One-hot encode the target variable\n# onehotencoder = OneHotEncoder()\n# y_train_encoded = onehotencoder.fit_transform(y_train.values.reshape(-1,1)).toarray()\n# y_test_encoded = onehotencoder.transform(y_test.values.reshape(-1,1)).toarray()\n\n# ===============================\n# Encode target labels (single source of truth)\n# ===============================\nfrom sklearn.preprocessing import LabelEncoder\n\nlabel_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded  = label_encoder.transform(y_test)\n","metadata":{"execution":{"iopub.status.busy":"2025-12-26T18:02:56.112178Z","iopub.execute_input":"2025-12-26T18:02:56.112421Z","iopub.status.idle":"2025-12-26T18:02:56.130076Z","shell.execute_reply.started":"2025-12-26T18:02:56.112405Z","shell.execute_reply":"2025-12-26T18:02:56.129031Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Identify string columns\nstring_cols = X_train.select_dtypes(include=['object']).columns\n\n# Encode string columns\nfor col in string_cols:\n    le = LabelEncoder()\n    X_train[col] = le.fit_transform(X_train[col])\n    X_test[col] = le.transform(X_test[col])","metadata":{"execution":{"iopub.status.busy":"2025-12-26T18:02:56.130988Z","iopub.execute_input":"2025-12-26T18:02:56.131178Z","iopub.status.idle":"2025-12-26T18:02:56.155959Z","shell.execute_reply.started":"2025-12-26T18:02:56.131162Z","shell.execute_reply":"2025-12-26T18:02:56.155205Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Assuming you already have `LabelEncoder` instance `label_encoder` for encoding the target variable\n\n# Encode target variables\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n\n# Evaluate models\nmodels = [\n    ('Naive Bayes', BNB_Classifier),\n    ('Decision Tree', DTC_Classifier),\n    ('KNN', KNN_Classifier),\n    ('Logistic Regression (OvR)', LGR_Classifier),\n    ('Random Forest', RF_Classifier),\n    ('SVM', SVM_Classifier)\n]\n\n\nfrom sklearn.model_selection import StratifiedKFold\n\nfor name, model in models:\n    print()\n    print(f\"================ {name} =================\")\n    print()\n\n    # ---- Cross-validation (skip SVM) ----\n    if name != 'SVM':\n        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n        cv_scores = cross_val_score(\n            model,\n            X_train,\n            y_train_encoded,\n            cv=skf,\n            scoring='f1_macro'\n        )\n        print(\"CV F1-Macro (Mean ± Std):\")\n        print(f\"{cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n        print()\n    else:\n        print(\"CV skipped for SVM due to computational constraints\")\n        print()\n\n    # ---- Train once ----\n    model.fit(X_train, y_train_encoded)\n\n    # ---- Test evaluation ----\n    y_pred = model.predict(X_test)\n\n    print(\"Test Accuracy:\")\n    print(metrics.accuracy_score(y_test_encoded, y_pred))\n    print()\n\n    print(\"Confusion Matrix:\")\n    print(metrics.confusion_matrix(y_test_encoded, y_pred))\n    print()\n\n    print(\"Classification Report:\")\n    print(metrics.classification_report(y_test_encoded, y_pred))\n","metadata":{"execution":{"iopub.status.busy":"2025-12-26T18:02:56.156868Z","iopub.execute_input":"2025-12-26T18:02:56.157106Z","iopub.status.idle":"2025-12-26T18:24:55.503323Z","shell.execute_reply.started":"2025-12-26T18:02:56.157083Z","shell.execute_reply":"2025-12-26T18:24:55.502155Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\n================ Naive Bayes =================\n\nCV F1-Macro (Mean ± Std):\n0.3908 ± 0.0105\n\nTest Accuracy:\n0.8537384477482768\n\nConfusion Matrix:\n[[7073    0    0    0    2    8    0    0    0    0   35   15   84    0\n     0  100   21    1]\n [   1    7    0    0    6    0    0    0    0  221   37    2    0    0\n     2    0    0    0]\n [   0    0    0   98    1    0    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0    0    0  452    0    0    0    3    0    0    0    0    0    0\n     0    0    0    0]\n [   9    0    0 1241 7344   43   19  427    0    0    6    1    3    0\n     0    0    0   14]\n [   0    0    0   13    0   14    0    0    0    0   14    0    0    0\n     0    0    0    0]\n [   0    0    0  206    0    1    0    0    0    0    1    0    0    0\n     0    0    0    0]\n [   0    0    0   29    4    1    3  731    0    0   10    0    0    0\n     0    0    0    0]\n [   0    0    0    0    0    0    0    0    0  142    0    0    0    0\n     0    0    0    0]\n [   0    0    0    0    0    0    0    0    0  634    0    0    0    1\n     9    0    0    0]\n [   0    1    0    0    0    0    0    0    0    1   37    0    0    0\n     0    2    0    0]\n [   2    1    0    0    0    0    0    0    0    3   30    6    2    0\n     0    1    0    2]\n [   4    0    0    0    0    0    0    0    0    7    0  678 2930    0\n     0   63    0    5]\n [   0    1    0   27   12    0    0    0    0  275    0   17    5 7123\n     2   13    0    3]\n [   0    9    0    0    3    0    0    0    3   48   16    2    0    0\n  1263    0    0    0]\n [   2    0    0    0    0    0    0    0    0    9    0   83  398    0\n   153    7    3    2]\n [   0    0    0    0    0    0    0    0    0    3    0    2    0    0\n     0    0    0    0]\n [   2    0    0    0    0    0    0    0    0    0    0    2    1    0\n     0    0    0    0]]\n\nClassification Report:\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       1.00      0.96      0.98      7339\n           1       0.37      0.03      0.05       276\n           2       0.00      0.00      0.00        99\n           3       0.22      0.99      0.36       455\n           4       1.00      0.81      0.89      9107\n           5       0.21      0.34      0.26        41\n           6       0.00      0.00      0.00       208\n           7       0.63      0.94      0.75       778\n           8       0.00      0.00      0.00       142\n           9       0.47      0.98      0.64       644\n          10       0.20      0.90      0.33        41\n          11       0.01      0.13      0.01        47\n          12       0.86      0.79      0.82      3687\n          13       1.00      0.95      0.98      7478\n          14       0.88      0.94      0.91      1344\n          15       0.04      0.01      0.02       657\n          16       0.00      0.00      0.00         5\n          17       0.00      0.00      0.00         5\n\n    accuracy                           0.85     32353\n   macro avg       0.38      0.49      0.39     32353\nweighted avg       0.90      0.85      0.87     32353\n\n\n================ Decision Tree =================\n\nCV F1-Macro (Mean ± Std):\n0.9519 ± 0.0269\n\nTest Accuracy:\n0.9922418322875777\n\nConfusion Matrix:\n[[7338    0    0    0    0    1    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0  259    0    0    0    0    0    0    0    5    0    0    0    0\n    11    1    0    0]\n [   0    0   99    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0    0    0  455    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0    0    0    0 9107    0    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0    0    0    0    0   41    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0    0    0    0    0    0  208    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0    0    0    0    0    0    0  778    0    0    0    0    0    0\n     0    0    0    0]\n [   0    0    0    0    0    0    0    0  142    0    0    0    0    0\n     0    0    0    0]\n [   0    3    0    0    0    0    0    0    2  631    0    0    0    3\n     3    2    0    0]\n [   2    0    0    0    0    0    0    0    0    0   39    0    0    0\n     0    0    0    0]\n [   1    0    0    0    0    0    0    0    0    0    0   46    0    0\n     0    0    0    0]\n [   0    0    0    0    0    0    0    0    0    0    0    0 3684    3\n     0    0    0    0]\n [   0    0    0    0    0    0    0    0    0    1    1    0    1 7474\n     0    0    1    0]\n [   0   11    0    0    0    0    0    0    0    2    0    1    0    0\n  1237   91    2    0]\n [   0    0    0    0    0    0    0    0    0    0    0    4    0    0\n    96  557    0    0]\n [   0    0    0    0    0    0    0    0    0    0    0    0    0    1\n     2    0    2    0]\n [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    5]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00      7339\n           1       0.95      0.94      0.94       276\n           2       1.00      1.00      1.00        99\n           3       1.00      1.00      1.00       455\n           4       1.00      1.00      1.00      9107\n           5       0.98      1.00      0.99        41\n           6       1.00      1.00      1.00       208\n           7       1.00      1.00      1.00       778\n           8       0.99      1.00      0.99       142\n           9       0.99      0.98      0.98       644\n          10       0.97      0.95      0.96        41\n          11       0.90      0.98      0.94        47\n          12       1.00      1.00      1.00      3687\n          13       1.00      1.00      1.00      7478\n          14       0.92      0.92      0.92      1344\n          15       0.86      0.85      0.85       657\n          16       0.40      0.40      0.40         5\n          17       1.00      1.00      1.00         5\n\n    accuracy                           0.99     32353\n   macro avg       0.94      0.95      0.94     32353\nweighted avg       0.99      0.99      0.99     32353\n\n\n================ KNN =================\n\nCV F1-Macro (Mean ± Std):\n0.8303 ± 0.0341\n\nTest Accuracy:\n0.9808982165486971\n\nConfusion Matrix:\n[[7312    0    0    0    5    1    0    0    0    0    0    0   19    2\n     0    0    0    0]\n [   1  235    0    0    3    0    3    0    3    8    2    1    0    1\n    16    3    0    0]\n [   0    0   72    3    0    0   24    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0    0    6  435    1    0    5    1    1    6    0    0    0    0\n     0    0    0    0]\n [   7    0    0    8 9088    2    1    0    0    0    0    0    1    0\n     0    0    0    0]\n [   0    0    0   11    0   20    4    3    0    0    3    0    0    0\n     0    0    0    0]\n [   0    0    7    4    0    1  194    0    1    1    0    0    0    0\n     0    0    0    0]\n [   0    0    0    2    5    1    1  769    0    0    0    0    0    0\n     0    0    0    0]\n [   0    0    0    0    0    0    3    0  133    6    0    0    0    0\n     0    0    0    0]\n [   0   10    1    4    0    0    1    1    7  615    0    0    0    1\n     3    1    0    0]\n [   0    1    0    0    0    2    0    1    0    0   36    0    0    0\n     1    0    0    0]\n [   1    6    0    0    0    0    0    0    0    1    0   35    4    0\n     0    0    0    0]\n [   5    0    0    0    0    0    0    0    0    0    0    3 3626    3\n     5   44    1    0]\n [   4    1    0    0    3    0    0    0    0    3    0    1   15 7448\n     0    2    0    1]\n [   0   15    0    0    0    0    0    4    0    5    0    3    0    1\n  1282   31    3    0]\n [   0    3    0    0    1    0    0    0    0    1    0    4   82    0\n   134  431    0    1]\n [   0    0    0    0    0    0    0    0    0    0    0    0    2    0\n     1    0    2    0]\n [   2    0    0    0    1    0    0    0    0    0    0    0    0    0\n     0    0    0    2]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00      7339\n           1       0.87      0.85      0.86       276\n           2       0.84      0.73      0.78        99\n           3       0.93      0.96      0.94       455\n           4       1.00      1.00      1.00      9107\n           5       0.74      0.49      0.59        41\n           6       0.82      0.93      0.87       208\n           7       0.99      0.99      0.99       778\n           8       0.92      0.94      0.93       142\n           9       0.95      0.95      0.95       644\n          10       0.88      0.88      0.88        41\n          11       0.74      0.74      0.74        47\n          12       0.97      0.98      0.98      3687\n          13       1.00      1.00      1.00      7478\n          14       0.89      0.95      0.92      1344\n          15       0.84      0.66      0.74       657\n          16       0.33      0.40      0.36         5\n          17       0.50      0.40      0.44         5\n\n    accuracy                           0.98     32353\n   macro avg       0.84      0.82      0.83     32353\nweighted avg       0.98      0.98      0.98     32353\n\n\n================ Logistic Regression (OvR) =================\n\nCV F1-Macro (Mean ± Std):\n0.6485 ± 0.0296\n\nTest Accuracy:\n0.9652582449850091\n\nConfusion Matrix:\n[[7327    4    0    2    0    0    0    0    0    0    0    0    0    3\n     0    3    0    0]\n [   0  212    0    0    0    0    0    0    0    1   17   11    0    0\n     1    1   33    0]\n [   0    0   66    0    0    0   30    0    0    0    0    0    0    0\n     0    0    3    0]\n [   0    0    5  403    0    0   32    0    0   15    0    0    0    0\n     0    0    0    0]\n [   0    0    0   15 9042    8    0    7    0    2    2    0    9    0\n     0    0   22    0]\n [   0    0    0    9    0    7    1   14    0    2    1    0    0    0\n     0    0    7    0]\n [   0    0  101    0    0    1  103    1    0    1    0    0    0    1\n     0    0    0    0]\n [   0    0    1    0    0    0    0  727    0   27    0    0    0    0\n     0    0   23    0]\n [   0    0    0    0    0    0    0    0  135    6    0    0    0    0\n     0    0    1    0]\n [   0    7    0    0    0    0    0    0   25  519    0    1    0    2\n     0    0   90    0]\n [   0    0    0    2    0    0    0    2    0    1   22    0    0    0\n     0    0   14    0]\n [   0    0    0    0    0    0    0    0    0    1   11    2    4    0\n    14    1   13    1]\n [   0    0    0    4    0    0    0    0    0    3    0    7 3649    0\n     0    6   11    7]\n [   0    0    0    0    0    0    0    0    1   33    0    1   22 7407\n     1    4    7    2]\n [   0    6    0    0    0    0    0  112    0   23    0   26    0    0\n  1147    0   30    0]\n [   0    0    0    0    0    0    0    0    0    1    0   10   28    0\n   149  457    8    4]\n [   0    0    0    0    0    0    0    0    0    3    0    0    2    0\n     0    0    0    0]\n [   0    0    0    0    0    0    0    0    0    0    0    1    0    0\n     0    0    0    4]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00      7339\n           1       0.93      0.77      0.84       276\n           2       0.38      0.67      0.49        99\n           3       0.93      0.89      0.91       455\n           4       1.00      0.99      1.00      9107\n           5       0.44      0.17      0.25        41\n           6       0.62      0.50      0.55       208\n           7       0.84      0.93      0.89       778\n           8       0.84      0.95      0.89       142\n           9       0.81      0.81      0.81       644\n          10       0.42      0.54      0.47        41\n          11       0.03      0.04      0.04        47\n          12       0.98      0.99      0.99      3687\n          13       1.00      0.99      0.99      7478\n          14       0.87      0.85      0.86      1344\n          15       0.97      0.70      0.81       657\n          16       0.00      0.00      0.00         5\n          17       0.22      0.80      0.35         5\n\n    accuracy                           0.97     32353\n   macro avg       0.68      0.70      0.67     32353\nweighted avg       0.97      0.97      0.97     32353\n\n\n================ Random Forest =================\n\nCV F1-Macro (Mean ± Std):\n0.8431 ± 0.0312\n\nTest Accuracy:\n0.9860291163106976\n\nConfusion Matrix:\n[[7339    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0  202    0    0    0    0    1    0    1   62    0    2    0    0\n     7    1    0    0]\n [   0    2   72    1    0    0   20    0    3    1    0    0    0    0\n     0    0    0    0]\n [   0    0    2  441    0    0    7    1    0    3    0    0    0    1\n     0    0    0    0]\n [   0    0    0    0 9107    0    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0    1    0    0    0   22    2    2    0   10    3    1    0    0\n     0    0    0    0]\n [   0    1    6    2    0    1  186    0    8    3    1    0    0    0\n     0    0    0    0]\n [   0    1    0    1    0    0    1  763    0    8    0    0    0    0\n     4    0    0    0]\n [   0    3    2    0    0    0    9    0  123    5    0    0    0    0\n     0    0    0    0]\n [   0    0    0    0    0    0    2    1    3  633    0    0    0    0\n     3    2    0    0]\n [   0    1    0    0    0    4    0    0    0    0   30    5    0    0\n     1    0    0    0]\n [   2    1    0    0    0    0    0    0    0    2    5   31    5    0\n     0    1    0    0]\n [   0    0    0    0    0    0    0    0    0    2    0    3 3676    0\n     4    0    2    0]\n [   0    1    0    0    1    0    0    0    0    0    0    0    2 7465\n     0    9    0    0]\n [   0    4    0    0    0    0    0    0    0   19    0    2    0    0\n  1318    0    1    0]\n [   1    0    0    0    1    0    0    0    0    0    0    2    0    1\n   161  490    1    0]\n [   0    0    0    0    0    0    0    0    0    0    0    0    2    0\n     2    0    1    0]\n [   0    0    0    0    2    0    0    0    0    0    0    0    0    0\n     0    1    0    2]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00      7339\n           1       0.93      0.73      0.82       276\n           2       0.88      0.73      0.80        99\n           3       0.99      0.97      0.98       455\n           4       1.00      1.00      1.00      9107\n           5       0.81      0.54      0.65        41\n           6       0.82      0.89      0.85       208\n           7       0.99      0.98      0.99       778\n           8       0.89      0.87      0.88       142\n           9       0.85      0.98      0.91       644\n          10       0.77      0.73      0.75        41\n          11       0.67      0.66      0.67        47\n          12       1.00      1.00      1.00      3687\n          13       1.00      1.00      1.00      7478\n          14       0.88      0.98      0.93      1344\n          15       0.97      0.75      0.84       657\n          16       0.20      0.20      0.20         5\n          17       1.00      0.40      0.57         5\n\n    accuracy                           0.99     32353\n   macro avg       0.87      0.80      0.82     32353\nweighted avg       0.99      0.99      0.99     32353\n\n\n================ SVM =================\n\nCV skipped for SVM due to computational constraints\n\nTest Accuracy:\n0.9614255246808642\n\nConfusion Matrix:\n[[7230    8    3    4    0    3    0    1    4    0    0    3    0    2\n     0    0   81    0]\n [   0  234    0    0    0    0    0    0    0    0   22   19    0    0\n     0    1    0    0]\n [   0    0   32    0    0    0   64    0    3    0    0    0    0    0\n     0    0    0    0]\n [   0    0    2  431    0    0   22    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0    0    0   15 9082    2    0    1    0    0    5    0    1    0\n     0    0    1    0]\n [   0    0    0   19    0    1    1    0    0    0   20    0    0    0\n     0    0    0    0]\n [   0    0    9    2    0    0  194    0    1    0    2    0    0    0\n     0    0    0    0]\n [   0    0    0    1    0    0    1  728    0   39    0    0    0    0\n     1    0    8    0]\n [   0    0    0    0    0    0    0    0  138    4    0    0    0    0\n     0    0    0    0]\n [   0    7    0    0    0    0    0    0   35  507    0    2    0    2\n     0    0   91    0]\n [   0    0    0    0    0    2    0    0    0    4   35    0    0    0\n     0    0    0    0]\n [   2    0    0    0    0    0    0    0    0    5    4   29    2    0\n     0    0    4    1]\n [   2    0    0    1    0    0    0    0    0    3    0   10 3510    0\n     0    2  158    1]\n [   5    0    0    0    0    0    0    0    1    6    0    5   16 7409\n     6    6   24    0]\n [   0   27    0    0    0    0    0  192    0   28    0   18    0    0\n  1065    0   14    0]\n [   0    4    0    0    0    0    0    0    0    5    0   11    0    0\n   149  475   12    1]\n [   0    0    0    0    0    0    0    0    0    3    0    1    1    0\n     0    0    0    0]\n [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    5]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      0.99      0.99      7339\n           1       0.84      0.85      0.84       276\n           2       0.70      0.32      0.44        99\n           3       0.91      0.95      0.93       455\n           4       1.00      1.00      1.00      9107\n           5       0.12      0.02      0.04        41\n           6       0.69      0.93      0.79       208\n           7       0.79      0.94      0.86       778\n           8       0.76      0.97      0.85       142\n           9       0.84      0.79      0.81       644\n          10       0.40      0.85      0.54        41\n          11       0.30      0.62      0.40        47\n          12       0.99      0.95      0.97      3687\n          13       1.00      0.99      1.00      7478\n          14       0.87      0.79      0.83      1344\n          15       0.98      0.72      0.83       657\n          16       0.00      0.00      0.00         5\n          17       0.62      1.00      0.77         5\n\n    accuracy                           0.96     32353\n   macro avg       0.71      0.76      0.72     32353\nweighted avg       0.98      0.96      0.97     32353\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Assuming you already have `LabelEncoder` instance `label_encoder` for encoding the target variable\n\n# Encode target variables\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n\nfrom sklearn.model_selection import StratifiedKFold\n\nfor name, model in models:\n    print()\n    print(f\"================ {name} =================\")\n    print()\n\n    # ---- Stratified 10-Fold CV ----\n    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n    cv_scores = cross_val_score(\n        model,\n        X_train,\n        y_train_encoded,\n        cv=skf,\n        scoring='f1_macro'\n    )\n\n    print(\"CV F1-Macro (Mean ± Std):\")\n    print(f\"{cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n    print()\n\n    # ---- Fit once on full training set ----\n    model.fit(X_train, y_train_encoded)\n\n    # ---- Test evaluation ----\n    y_pred = model.predict(X_test)\n\n    print(\"Test Accuracy:\")\n    print(metrics.accuracy_score(y_test_encoded, y_pred))\n    print()\n\n    print(\"Confusion Matrix:\")\n    print(metrics.confusion_matrix(y_test_encoded, y_pred))\n    print()\n\n    print(\"Classification Report:\")\n    print(\n    metrics.classification_report(\n        y_test_encoded,\n        y_pred,\n        zero_division=0,\n        output_dict=False\n    )\n)\n","metadata":{"execution":{"iopub.status.busy":"2025-12-26T18:24:55.504129Z","iopub.execute_input":"2025-12-26T18:24:55.504407Z","iopub.status.idle":"2025-12-26T20:05:44.576028Z","shell.execute_reply.started":"2025-12-26T18:24:55.504384Z","shell.execute_reply":"2025-12-26T20:05:44.573925Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\n================ Naive Bayes =================\n\nCV F1-Macro (Mean ± Std):\n0.3908 ± 0.0105\n\nTest Accuracy:\n0.8537384477482768\n\nConfusion Matrix:\n[[7073    0    0    0    2    8    0    0    0    0   35   15   84    0\n     0  100   21    1]\n [   1    7    0    0    6    0    0    0    0  221   37    2    0    0\n     2    0    0    0]\n [   0    0    0   98    1    0    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0    0    0  452    0    0    0    3    0    0    0    0    0    0\n     0    0    0    0]\n [   9    0    0 1241 7344   43   19  427    0    0    6    1    3    0\n     0    0    0   14]\n [   0    0    0   13    0   14    0    0    0    0   14    0    0    0\n     0    0    0    0]\n [   0    0    0  206    0    1    0    0    0    0    1    0    0    0\n     0    0    0    0]\n [   0    0    0   29    4    1    3  731    0    0   10    0    0    0\n     0    0    0    0]\n [   0    0    0    0    0    0    0    0    0  142    0    0    0    0\n     0    0    0    0]\n [   0    0    0    0    0    0    0    0    0  634    0    0    0    1\n     9    0    0    0]\n [   0    1    0    0    0    0    0    0    0    1   37    0    0    0\n     0    2    0    0]\n [   2    1    0    0    0    0    0    0    0    3   30    6    2    0\n     0    1    0    2]\n [   4    0    0    0    0    0    0    0    0    7    0  678 2930    0\n     0   63    0    5]\n [   0    1    0   27   12    0    0    0    0  275    0   17    5 7123\n     2   13    0    3]\n [   0    9    0    0    3    0    0    0    3   48   16    2    0    0\n  1263    0    0    0]\n [   2    0    0    0    0    0    0    0    0    9    0   83  398    0\n   153    7    3    2]\n [   0    0    0    0    0    0    0    0    0    3    0    2    0    0\n     0    0    0    0]\n [   2    0    0    0    0    0    0    0    0    0    0    2    1    0\n     0    0    0    0]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      0.96      0.98      7339\n           1       0.37      0.03      0.05       276\n           2       0.00      0.00      0.00        99\n           3       0.22      0.99      0.36       455\n           4       1.00      0.81      0.89      9107\n           5       0.21      0.34      0.26        41\n           6       0.00      0.00      0.00       208\n           7       0.63      0.94      0.75       778\n           8       0.00      0.00      0.00       142\n           9       0.47      0.98      0.64       644\n          10       0.20      0.90      0.33        41\n          11       0.01      0.13      0.01        47\n          12       0.86      0.79      0.82      3687\n          13       1.00      0.95      0.98      7478\n          14       0.88      0.94      0.91      1344\n          15       0.04      0.01      0.02       657\n          16       0.00      0.00      0.00         5\n          17       0.00      0.00      0.00         5\n\n    accuracy                           0.85     32353\n   macro avg       0.38      0.49      0.39     32353\nweighted avg       0.90      0.85      0.87     32353\n\n\n================ Decision Tree =================\n\nCV F1-Macro (Mean ± Std):\n0.9519 ± 0.0269\n\nTest Accuracy:\n0.9922418322875777\n\nConfusion Matrix:\n[[7338    0    0    0    0    1    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0  259    0    0    0    0    0    0    0    5    0    0    0    0\n    11    1    0    0]\n [   0    0   99    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0    0    0  455    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0    0    0    0 9107    0    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0    0    0    0    0   41    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0    0    0    0    0    0  208    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0    0    0    0    0    0    0  778    0    0    0    0    0    0\n     0    0    0    0]\n [   0    0    0    0    0    0    0    0  142    0    0    0    0    0\n     0    0    0    0]\n [   0    3    0    0    0    0    0    0    2  631    0    0    0    3\n     3    2    0    0]\n [   2    0    0    0    0    0    0    0    0    0   39    0    0    0\n     0    0    0    0]\n [   1    0    0    0    0    0    0    0    0    0    0   46    0    0\n     0    0    0    0]\n [   0    0    0    0    0    0    0    0    0    0    0    0 3684    3\n     0    0    0    0]\n [   0    0    0    0    0    0    0    0    0    1    1    0    1 7474\n     0    0    1    0]\n [   0   11    0    0    0    0    0    0    0    2    0    1    0    0\n  1237   91    2    0]\n [   0    0    0    0    0    0    0    0    0    0    0    4    0    0\n    96  557    0    0]\n [   0    0    0    0    0    0    0    0    0    0    0    0    0    1\n     2    0    2    0]\n [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    5]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00      7339\n           1       0.95      0.94      0.94       276\n           2       1.00      1.00      1.00        99\n           3       1.00      1.00      1.00       455\n           4       1.00      1.00      1.00      9107\n           5       0.98      1.00      0.99        41\n           6       1.00      1.00      1.00       208\n           7       1.00      1.00      1.00       778\n           8       0.99      1.00      0.99       142\n           9       0.99      0.98      0.98       644\n          10       0.97      0.95      0.96        41\n          11       0.90      0.98      0.94        47\n          12       1.00      1.00      1.00      3687\n          13       1.00      1.00      1.00      7478\n          14       0.92      0.92      0.92      1344\n          15       0.86      0.85      0.85       657\n          16       0.40      0.40      0.40         5\n          17       1.00      1.00      1.00         5\n\n    accuracy                           0.99     32353\n   macro avg       0.94      0.95      0.94     32353\nweighted avg       0.99      0.99      0.99     32353\n\n\n================ KNN =================\n\nCV F1-Macro (Mean ± Std):\n0.8303 ± 0.0341\n\nTest Accuracy:\n0.9808982165486971\n\nConfusion Matrix:\n[[7312    0    0    0    5    1    0    0    0    0    0    0   19    2\n     0    0    0    0]\n [   1  235    0    0    3    0    3    0    3    8    2    1    0    1\n    16    3    0    0]\n [   0    0   72    3    0    0   24    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0    0    6  435    1    0    5    1    1    6    0    0    0    0\n     0    0    0    0]\n [   7    0    0    8 9088    2    1    0    0    0    0    0    1    0\n     0    0    0    0]\n [   0    0    0   11    0   20    4    3    0    0    3    0    0    0\n     0    0    0    0]\n [   0    0    7    4    0    1  194    0    1    1    0    0    0    0\n     0    0    0    0]\n [   0    0    0    2    5    1    1  769    0    0    0    0    0    0\n     0    0    0    0]\n [   0    0    0    0    0    0    3    0  133    6    0    0    0    0\n     0    0    0    0]\n [   0   10    1    4    0    0    1    1    7  615    0    0    0    1\n     3    1    0    0]\n [   0    1    0    0    0    2    0    1    0    0   36    0    0    0\n     1    0    0    0]\n [   1    6    0    0    0    0    0    0    0    1    0   35    4    0\n     0    0    0    0]\n [   5    0    0    0    0    0    0    0    0    0    0    3 3626    3\n     5   44    1    0]\n [   4    1    0    0    3    0    0    0    0    3    0    1   15 7448\n     0    2    0    1]\n [   0   15    0    0    0    0    0    4    0    5    0    3    0    1\n  1282   31    3    0]\n [   0    3    0    0    1    0    0    0    0    1    0    4   82    0\n   134  431    0    1]\n [   0    0    0    0    0    0    0    0    0    0    0    0    2    0\n     1    0    2    0]\n [   2    0    0    0    1    0    0    0    0    0    0    0    0    0\n     0    0    0    2]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00      7339\n           1       0.87      0.85      0.86       276\n           2       0.84      0.73      0.78        99\n           3       0.93      0.96      0.94       455\n           4       1.00      1.00      1.00      9107\n           5       0.74      0.49      0.59        41\n           6       0.82      0.93      0.87       208\n           7       0.99      0.99      0.99       778\n           8       0.92      0.94      0.93       142\n           9       0.95      0.95      0.95       644\n          10       0.88      0.88      0.88        41\n          11       0.74      0.74      0.74        47\n          12       0.97      0.98      0.98      3687\n          13       1.00      1.00      1.00      7478\n          14       0.89      0.95      0.92      1344\n          15       0.84      0.66      0.74       657\n          16       0.33      0.40      0.36         5\n          17       0.50      0.40      0.44         5\n\n    accuracy                           0.98     32353\n   macro avg       0.84      0.82      0.83     32353\nweighted avg       0.98      0.98      0.98     32353\n\n\n================ Logistic Regression (OvR) =================\n\nCV F1-Macro (Mean ± Std):\n0.6485 ± 0.0296\n\nTest Accuracy:\n0.9652582449850091\n\nConfusion Matrix:\n[[7327    4    0    2    0    0    0    0    0    0    0    0    0    3\n     0    3    0    0]\n [   0  212    0    0    0    0    0    0    0    1   17   11    0    0\n     1    1   33    0]\n [   0    0   66    0    0    0   30    0    0    0    0    0    0    0\n     0    0    3    0]\n [   0    0    5  403    0    0   32    0    0   15    0    0    0    0\n     0    0    0    0]\n [   0    0    0   15 9042    8    0    7    0    2    2    0    9    0\n     0    0   22    0]\n [   0    0    0    9    0    7    1   14    0    2    1    0    0    0\n     0    0    7    0]\n [   0    0  101    0    0    1  103    1    0    1    0    0    0    1\n     0    0    0    0]\n [   0    0    1    0    0    0    0  727    0   27    0    0    0    0\n     0    0   23    0]\n [   0    0    0    0    0    0    0    0  135    6    0    0    0    0\n     0    0    1    0]\n [   0    7    0    0    0    0    0    0   25  519    0    1    0    2\n     0    0   90    0]\n [   0    0    0    2    0    0    0    2    0    1   22    0    0    0\n     0    0   14    0]\n [   0    0    0    0    0    0    0    0    0    1   11    2    4    0\n    14    1   13    1]\n [   0    0    0    4    0    0    0    0    0    3    0    7 3649    0\n     0    6   11    7]\n [   0    0    0    0    0    0    0    0    1   33    0    1   22 7407\n     1    4    7    2]\n [   0    6    0    0    0    0    0  112    0   23    0   26    0    0\n  1147    0   30    0]\n [   0    0    0    0    0    0    0    0    0    1    0   10   28    0\n   149  457    8    4]\n [   0    0    0    0    0    0    0    0    0    3    0    0    2    0\n     0    0    0    0]\n [   0    0    0    0    0    0    0    0    0    0    0    1    0    0\n     0    0    0    4]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00      7339\n           1       0.93      0.77      0.84       276\n           2       0.38      0.67      0.49        99\n           3       0.93      0.89      0.91       455\n           4       1.00      0.99      1.00      9107\n           5       0.44      0.17      0.25        41\n           6       0.62      0.50      0.55       208\n           7       0.84      0.93      0.89       778\n           8       0.84      0.95      0.89       142\n           9       0.81      0.81      0.81       644\n          10       0.42      0.54      0.47        41\n          11       0.03      0.04      0.04        47\n          12       0.98      0.99      0.99      3687\n          13       1.00      0.99      0.99      7478\n          14       0.87      0.85      0.86      1344\n          15       0.97      0.70      0.81       657\n          16       0.00      0.00      0.00         5\n          17       0.22      0.80      0.35         5\n\n    accuracy                           0.97     32353\n   macro avg       0.68      0.70      0.67     32353\nweighted avg       0.97      0.97      0.97     32353\n\n\n================ Random Forest =================\n\nCV F1-Macro (Mean ± Std):\n0.8431 ± 0.0312\n\nTest Accuracy:\n0.9860291163106976\n\nConfusion Matrix:\n[[7339    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0  202    0    0    0    0    1    0    1   62    0    2    0    0\n     7    1    0    0]\n [   0    2   72    1    0    0   20    0    3    1    0    0    0    0\n     0    0    0    0]\n [   0    0    2  441    0    0    7    1    0    3    0    0    0    1\n     0    0    0    0]\n [   0    0    0    0 9107    0    0    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0    1    0    0    0   22    2    2    0   10    3    1    0    0\n     0    0    0    0]\n [   0    1    6    2    0    1  186    0    8    3    1    0    0    0\n     0    0    0    0]\n [   0    1    0    1    0    0    1  763    0    8    0    0    0    0\n     4    0    0    0]\n [   0    3    2    0    0    0    9    0  123    5    0    0    0    0\n     0    0    0    0]\n [   0    0    0    0    0    0    2    1    3  633    0    0    0    0\n     3    2    0    0]\n [   0    1    0    0    0    4    0    0    0    0   30    5    0    0\n     1    0    0    0]\n [   2    1    0    0    0    0    0    0    0    2    5   31    5    0\n     0    1    0    0]\n [   0    0    0    0    0    0    0    0    0    2    0    3 3676    0\n     4    0    2    0]\n [   0    1    0    0    1    0    0    0    0    0    0    0    2 7465\n     0    9    0    0]\n [   0    4    0    0    0    0    0    0    0   19    0    2    0    0\n  1318    0    1    0]\n [   1    0    0    0    1    0    0    0    0    0    0    2    0    1\n   161  490    1    0]\n [   0    0    0    0    0    0    0    0    0    0    0    0    2    0\n     2    0    1    0]\n [   0    0    0    0    2    0    0    0    0    0    0    0    0    0\n     0    1    0    2]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00      7339\n           1       0.93      0.73      0.82       276\n           2       0.88      0.73      0.80        99\n           3       0.99      0.97      0.98       455\n           4       1.00      1.00      1.00      9107\n           5       0.81      0.54      0.65        41\n           6       0.82      0.89      0.85       208\n           7       0.99      0.98      0.99       778\n           8       0.89      0.87      0.88       142\n           9       0.85      0.98      0.91       644\n          10       0.77      0.73      0.75        41\n          11       0.67      0.66      0.67        47\n          12       1.00      1.00      1.00      3687\n          13       1.00      1.00      1.00      7478\n          14       0.88      0.98      0.93      1344\n          15       0.97      0.75      0.84       657\n          16       0.20      0.20      0.20         5\n          17       1.00      0.40      0.57         5\n\n    accuracy                           0.99     32353\n   macro avg       0.87      0.80      0.82     32353\nweighted avg       0.99      0.99      0.99     32353\n\n\n================ SVM =================\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"CV F1-Macro (Mean ± Std):\n0.7112 ± 0.0263\n\nTest Accuracy:\n0.9614255246808642\n\nConfusion Matrix:\n[[7230    8    3    4    0    3    0    1    4    0    0    3    0    2\n     0    0   81    0]\n [   0  234    0    0    0    0    0    0    0    0   22   19    0    0\n     0    1    0    0]\n [   0    0   32    0    0    0   64    0    3    0    0    0    0    0\n     0    0    0    0]\n [   0    0    2  431    0    0   22    0    0    0    0    0    0    0\n     0    0    0    0]\n [   0    0    0   15 9082    2    0    1    0    0    5    0    1    0\n     0    0    1    0]\n [   0    0    0   19    0    1    1    0    0    0   20    0    0    0\n     0    0    0    0]\n [   0    0    9    2    0    0  194    0    1    0    2    0    0    0\n     0    0    0    0]\n [   0    0    0    1    0    0    1  728    0   39    0    0    0    0\n     1    0    8    0]\n [   0    0    0    0    0    0    0    0  138    4    0    0    0    0\n     0    0    0    0]\n [   0    7    0    0    0    0    0    0   35  507    0    2    0    2\n     0    0   91    0]\n [   0    0    0    0    0    2    0    0    0    4   35    0    0    0\n     0    0    0    0]\n [   2    0    0    0    0    0    0    0    0    5    4   29    2    0\n     0    0    4    1]\n [   2    0    0    1    0    0    0    0    0    3    0   10 3510    0\n     0    2  158    1]\n [   5    0    0    0    0    0    0    0    1    6    0    5   16 7409\n     6    6   24    0]\n [   0   27    0    0    0    0    0  192    0   28    0   18    0    0\n  1065    0   14    0]\n [   0    4    0    0    0    0    0    0    0    5    0   11    0    0\n   149  475   12    1]\n [   0    0    0    0    0    0    0    0    0    3    0    1    1    0\n     0    0    0    0]\n [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    5]]\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      0.99      0.99      7339\n           1       0.84      0.85      0.84       276\n           2       0.70      0.32      0.44        99\n           3       0.91      0.95      0.93       455\n           4       1.00      1.00      1.00      9107\n           5       0.12      0.02      0.04        41\n           6       0.69      0.93      0.79       208\n           7       0.79      0.94      0.86       778\n           8       0.76      0.97      0.85       142\n           9       0.84      0.79      0.81       644\n          10       0.40      0.85      0.54        41\n          11       0.30      0.62      0.40        47\n          12       0.99      0.95      0.97      3687\n          13       1.00      0.99      1.00      7478\n          14       0.87      0.79      0.83      1344\n          15       0.98      0.72      0.83       657\n          16       0.00      0.00      0.00         5\n          17       0.62      1.00      0.77         5\n\n    accuracy                           0.96     32353\n   macro avg       0.71      0.76      0.72     32353\nweighted avg       0.98      0.96      0.97     32353\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# PREDICTING FOR TEST DATA\npred_knn = KNN_Classifier.predict(X_test)\npred_NB = BNB_Classifier.predict(X_test)\npred_log = LGR_Classifier.predict(X_test)\npred_dt = DTC_Classifier.predict(X_test)\n\nprint(\"KNN: \", pred_knn)\nprint(\"BNB: \", pred_NB)\nprint(\"LGR: \", pred_log)\nprint(\"DTC: \", pred_dt)","metadata":{"execution":{"iopub.status.busy":"2025-12-26T20:05:44.577195Z","iopub.execute_input":"2025-12-26T20:05:44.578511Z","iopub.status.idle":"2025-12-26T20:05:51.947553Z","shell.execute_reply.started":"2025-12-26T20:05:44.578486Z","shell.execute_reply":"2025-12-26T20:05:51.946135Z"},"trusted":true},"outputs":[{"name":"stdout","text":"KNN:  [12  4 13 ...  0  4 13]\nBNB:  [11  4 13 ...  0  4 13]\nLGR:  [12  4 13 ...  0  4 13]\nDTC:  [12  4 13 ...  0  4 13]\n","output_type":"stream"}],"execution_count":8}]}